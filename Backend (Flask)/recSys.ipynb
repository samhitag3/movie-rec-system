{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie dataframe dimensions: (9742, 3)\n",
      "Ratings dataframe dimensions: (100836, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load in data from csv files\n",
    "movies_df = pd.read_csv(\"./Data/ml-latest-small/movies.csv\")\n",
    "ratings_df = pd.read_csv(\"./Data/ml-latest-small/ratings.csv\")\n",
    "\n",
    "print(f\"Movie dataframe dimensions: {movies_df.shape}\")\n",
    "print(f\"Ratings dataframe dimensions: {ratings_df.shape}\")\n",
    "\n",
    "# get number of unique users and movies\n",
    "n_users = len(ratings_df.userId.unique())\n",
    "n_items = len(ratings_df.movieId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # create user and item embeddings\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.movie_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        # fills weights with values from a uniform distribution [0, 0.5]\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.movie_factors.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        # matrix multiplication between user and item factors, and then concatenates them to one column\n",
    "        return (self.user_factors(data[:,0])*self.movie_factors(data[:,1])).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        self.ratings = ratings\n",
    "\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.ratings.movieId.values)\n",
    "        self.lookup = dict(zip(le.transform(self.ratings.movieId.values), self.ratings.movieId.values))\n",
    "\n",
    "        self.ratings.userId = preprocessing.LabelEncoder().fit_transform(self.ratings.userId.values)\n",
    "        self.ratings.movieId = preprocessing.LabelEncoder().fit_transform(self.ratings.movieId.values)\n",
    "\n",
    "        self.x = torch.tensor(self.ratings.drop(['rating', 'timestamp'], axis=1).values)\n",
    "        self.y = torch.tensor(self.ratings['rating'].values)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return (self.x[item], self.y[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: False\n",
      "user_factors.weight tensor([[0.0487, 0.0242, 0.0120,  ..., 0.0225, 0.0057, 0.0103],\n",
      "        [0.0098, 0.0423, 0.0359,  ..., 0.0166, 0.0179, 0.0354],\n",
      "        [0.0164, 0.0362, 0.0447,  ..., 0.0002, 0.0369, 0.0400],\n",
      "        ...,\n",
      "        [0.0172, 0.0274, 0.0296,  ..., 0.0009, 0.0210, 0.0441],\n",
      "        [0.0109, 0.0359, 0.0260,  ..., 0.0358, 0.0104, 0.0041],\n",
      "        [0.0108, 0.0115, 0.0242,  ..., 0.0013, 0.0258, 0.0490]])\n",
      "movie_factors.weight tensor([[0.0337, 0.0140, 0.0063,  ..., 0.0495, 0.0277, 0.0174],\n",
      "        [0.0023, 0.0182, 0.0381,  ..., 0.0175, 0.0248, 0.0114],\n",
      "        [0.0280, 0.0083, 0.0405,  ..., 0.0498, 0.0039, 0.0478],\n",
      "        ...,\n",
      "        [0.0043, 0.0435, 0.0383,  ..., 0.0166, 0.0294, 0.0338],\n",
      "        [0.0330, 0.0232, 0.0454,  ..., 0.0351, 0.0314, 0.0309],\n",
      "        [0.0171, 0.0410, 0.0056,  ..., 0.0157, 0.0431, 0.0095]])\n",
      "iter #0 Loss: 11.062081646798227\n",
      "iter #1 Loss: 4.745890641272975\n",
      "iter #2 Loss: 2.473601130815932\n",
      "iter #3 Loss: 1.7215600473626615\n",
      "iter #4 Loss: 1.3462180419621734\n",
      "iter #5 Loss: 1.1288880177106955\n",
      "iter #6 Loss: 0.991515134343036\n",
      "iter #7 Loss: 0.9004816571770585\n",
      "iter #8 Loss: 0.8373722719208239\n",
      "iter #9 Loss: 0.7920415171511888\n",
      "iter #10 Loss: 0.7592109806343988\n",
      "iter #11 Loss: 0.7344403959394712\n",
      "iter #12 Loss: 0.7158491275259081\n",
      "iter #13 Loss: 0.7014239866494527\n",
      "iter #14 Loss: 0.6904942760537118\n",
      "iter #15 Loss: 0.6816300584882649\n",
      "iter #16 Loss: 0.6752090303577142\n",
      "iter #17 Loss: 0.6695442958380365\n",
      "iter #18 Loss: 0.6656055975005711\n",
      "iter #19 Loss: 0.6629619824931706\n",
      "iter #20 Loss: 0.6605298663229506\n",
      "iter #21 Loss: 0.6590177655446953\n",
      "iter #22 Loss: 0.6578429795158696\n",
      "iter #23 Loss: 0.6569541892424453\n",
      "iter #24 Loss: 0.6559481421097886\n",
      "iter #25 Loss: 0.6559145199465872\n",
      "iter #26 Loss: 0.6546163395198469\n",
      "iter #27 Loss: 0.6538530222050429\n",
      "iter #28 Loss: 0.6531022844959031\n",
      "iter #29 Loss: 0.6523359577894816\n",
      "iter #30 Loss: 0.6507787445777564\n",
      "iter #31 Loss: 0.6495901034568167\n",
      "iter #32 Loss: 0.6477426743219952\n",
      "iter #33 Loss: 0.6455290072460464\n",
      "iter #34 Loss: 0.643053593596226\n",
      "iter #35 Loss: 0.6399684412603451\n",
      "iter #36 Loss: 0.6362079916720463\n",
      "iter #37 Loss: 0.6317786923444211\n",
      "iter #38 Loss: 0.6268949972720921\n",
      "iter #39 Loss: 0.6208667862536338\n",
      "iter #40 Loss: 0.614277361840161\n",
      "iter #41 Loss: 0.6063238459492698\n",
      "iter #42 Loss: 0.5984099067482852\n",
      "iter #43 Loss: 0.5893029404548824\n",
      "iter #44 Loss: 0.5798608236355225\n",
      "iter #45 Loss: 0.5696707850104661\n",
      "iter #46 Loss: 0.5595887163417593\n",
      "iter #47 Loss: 0.5493934744505713\n",
      "iter #48 Loss: 0.5391444595256433\n",
      "iter #49 Loss: 0.5292288223045126\n",
      "iter #50 Loss: 0.5194370915290668\n",
      "iter #51 Loss: 0.5100523007627066\n",
      "iter #52 Loss: 0.5013888058096624\n",
      "iter #53 Loss: 0.49268461298670263\n",
      "iter #54 Loss: 0.4847242111708912\n",
      "iter #55 Loss: 0.47705309962863246\n",
      "iter #56 Loss: 0.4700213205542056\n",
      "iter #57 Loss: 0.4633860907654472\n",
      "iter #58 Loss: 0.4571385999129811\n",
      "iter #59 Loss: 0.4510405996653634\n",
      "iter #60 Loss: 0.44550646518163267\n",
      "iter #61 Loss: 0.44011043619156487\n",
      "iter #62 Loss: 0.43490189540809787\n",
      "iter #63 Loss: 0.4303827082293893\n",
      "iter #64 Loss: 0.4257155167799311\n",
      "iter #65 Loss: 0.4214453181715181\n",
      "iter #66 Loss: 0.4173577814008379\n",
      "iter #67 Loss: 0.41343901972026387\n",
      "iter #68 Loss: 0.40993002769986386\n",
      "iter #69 Loss: 0.4062861939750347\n",
      "iter #70 Loss: 0.40303666227813906\n",
      "iter #71 Loss: 0.39996224518884255\n",
      "iter #72 Loss: 0.3968598435675432\n",
      "iter #73 Loss: 0.3938967088606152\n",
      "iter #74 Loss: 0.3910703620481007\n",
      "iter #75 Loss: 0.3885021010026109\n",
      "iter #76 Loss: 0.3857636113419448\n",
      "iter #77 Loss: 0.3833646120191528\n",
      "iter #78 Loss: 0.3810931542878829\n",
      "iter #79 Loss: 0.3788423556172606\n",
      "iter #80 Loss: 0.3768330945959551\n",
      "iter #81 Loss: 0.3744546736822213\n",
      "iter #82 Loss: 0.37251635640859604\n",
      "iter #83 Loss: 0.3705942248216438\n",
      "iter #84 Loss: 0.3686814110555927\n",
      "iter #85 Loss: 0.3670099947582647\n",
      "iter #86 Loss: 0.36520149659006124\n",
      "iter #87 Loss: 0.3635275643413442\n",
      "iter #88 Loss: 0.3619373354512423\n",
      "iter #89 Loss: 0.36033500558909426\n",
      "iter #90 Loss: 0.358927134235347\n",
      "iter #91 Loss: 0.3575031735229916\n",
      "iter #92 Loss: 0.35618784237028983\n",
      "iter #93 Loss: 0.3547390664592007\n",
      "iter #94 Loss: 0.3537020365787944\n",
      "iter #95 Loss: 0.35220066416384604\n",
      "iter #96 Loss: 0.3510787599356041\n",
      "iter #97 Loss: 0.35002256322860115\n",
      "iter #98 Loss: 0.3487611934542656\n",
      "iter #99 Loss: 0.34753929536203443\n",
      "iter #100 Loss: 0.3467908744430784\n",
      "iter #101 Loss: 0.34563476365381085\n",
      "iter #102 Loss: 0.34472120708317927\n",
      "iter #103 Loss: 0.34373247453252675\n",
      "iter #104 Loss: 0.3427450842966283\n",
      "iter #105 Loss: 0.3419257002471365\n",
      "iter #106 Loss: 0.3410306741592243\n",
      "iter #107 Loss: 0.34014426069665077\n",
      "iter #108 Loss: 0.33927462176244877\n",
      "iter #109 Loss: 0.3386415012067345\n",
      "iter #110 Loss: 0.33779084582241053\n",
      "iter #111 Loss: 0.3369536743059679\n",
      "iter #112 Loss: 0.3362598119086118\n",
      "iter #113 Loss: 0.335670455912043\n",
      "iter #114 Loss: 0.334988787165148\n",
      "iter #115 Loss: 0.33421336596614215\n",
      "iter #116 Loss: 0.33352947861031834\n",
      "iter #117 Loss: 0.3330579499151501\n",
      "iter #118 Loss: 0.33243988809851827\n",
      "iter #119 Loss: 0.33167586878395927\n",
      "iter #120 Loss: 0.33107430824471\n",
      "iter #121 Loss: 0.3306564537779934\n",
      "iter #122 Loss: 0.3300674399786492\n",
      "iter #123 Loss: 0.32951271498036866\n",
      "iter #124 Loss: 0.32903403276341214\n",
      "iter #125 Loss: 0.32846675414194915\n",
      "iter #126 Loss: 0.3278223980917846\n",
      "iter #127 Loss: 0.32749119832128437\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = Model(n_users, n_items, n_factors=8)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    # prints the parameters who's changes will be recorded\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "# enable GPU if you have a GPU\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# MSE loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train data\n",
    "train_set = MovieDataset(ratings_df)\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)\n",
    "\n",
    "for it in range(num_epochs):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[ 1.2726e+00,  1.8067e+00,  7.1121e-01,  ...,  6.9756e-01,\n",
      "          1.4878e+00,  1.6245e+00],\n",
      "        [ 1.1304e+00,  5.0090e-01,  1.2233e+00,  ...,  1.0290e+00,\n",
      "          2.9691e-01,  9.3482e-01],\n",
      "        [ 5.5068e-04, -5.4346e-01,  3.2296e-01,  ..., -1.0895e+00,\n",
      "          1.5022e+00, -1.4924e+00],\n",
      "        ...,\n",
      "        [-2.4351e-01,  4.0455e-01,  2.7986e+00,  ...,  7.8791e-01,\n",
      "          1.6341e+00,  1.4713e+00],\n",
      "        [ 1.0527e+00,  1.4847e+00,  1.4288e+00,  ...,  2.2886e-01,\n",
      "          5.8942e-01,  8.6957e-01],\n",
      "        [ 9.3817e-01,  7.0492e-01,  1.4768e+00,  ...,  1.4043e+00,\n",
      "          1.4756e+00, -6.3685e-02]])\n",
      "movie_factors.weight tensor([[0.8128, 0.4463, 0.2855,  ..., 0.5901, 0.4254, 0.3448],\n",
      "        [0.5649, 0.3949, 0.2103,  ..., 0.5250, 0.2626, 0.6367],\n",
      "        [0.6031, 0.1798, 0.3586,  ..., 0.6429, 0.1892, 0.6468],\n",
      "        ...,\n",
      "        [0.3847, 0.4246, 0.4158,  ..., 0.3955, 0.4096, 0.4150],\n",
      "        [0.4275, 0.4190, 0.4432,  ..., 0.4302, 0.4254, 0.4016],\n",
      "        [0.5109, 0.5340, 0.4995,  ..., 0.5075, 0.5371, 0.4208]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t Miracle on 34th Street (1994)\n",
      "\t Go Fish (1994)\n",
      "\t Some Like It Hot (1959)\n",
      "\t Piano, The (1993)\n",
      "\t What's Eating Gilbert Grape (1993)\n",
      "\t Philadelphia (1993)\n",
      "\t Queen Margot (Reine Margot, La) (1994)\n",
      "\t Gigi (1958)\n",
      "\t Real Genius (1985)\n",
      "\t Shall We Dance (1937)\n",
      "Cluster #1\n",
      "\t Poetic Justice (1993)\n",
      "\t Bread and Chocolate (Pane e cioccolata) (1973)\n",
      "\t Kissed (1996)\n",
      "\t Super Mario Bros. (1993)\n",
      "\t Unlawful Entry (1992)\n",
      "\t NeverEnding Story III, The (1994)\n",
      "\t Jefferson in Paris (1995)\n",
      "\t Body Shots (1999)\n",
      "\t Everybody's Famous! (Iedereen beroemd!) (2000)\n",
      "\t Sunset Park (1996)\n",
      "Cluster #2\n",
      "\t How to Make an American Quilt (1995)\n",
      "\t North (1994)\n",
      "\t Down to Earth (2001)\n",
      "\t Three Colors: Blue (Trois couleurs: Bleu) (1993)\n",
      "\t I'll Do Anything (1994)\n",
      "\t Speechless (1994)\n",
      "\t Mary Reilly (1996)\n",
      "\t Babe, The (1992)\n",
      "\t Top Hat (1935)\n",
      "\t Jungle2Jungle (a.k.a. Jungle 2 Jungle) (1997)\n",
      "Cluster #3\n",
      "\t Singin' in the Rain (1952)\n",
      "\t Dangerous Minds (1995)\n",
      "\t Run Silent Run Deep (1958)\n",
      "\t Say Anything... (1989)\n",
      "\t Sleeping Beauty (1959)\n",
      "\t Powder (1995)\n",
      "\t Three to Tango (1999)\n",
      "\t Age of Innocence, The (1993)\n",
      "\t Free Willy (1993)\n",
      "\t Adventures of Pinocchio, The (1996)\n",
      "Cluster #4\n",
      "\t Chungking Express (Chung Hing sam lam) (1994)\n",
      "\t Robin Hood: Men in Tights (1993)\n",
      "\t Puppet Masters, The (1994)\n",
      "\t Mixed Nuts (1994)\n",
      "\t Sudden Death (1995)\n",
      "\t In the Line of Fire (1993)\n",
      "\t Foxfire (1996)\n",
      "\t Love and Death (1975)\n",
      "\t Poseidon Adventure, The (1972)\n",
      "\t Specialist, The (1994)\n",
      "Cluster #5\n",
      "\t Just Cause (1995)\n",
      "\t Perfect World, A (1993)\n",
      "\t Restoration (1995)\n",
      "\t My Dog Skip (1999)\n",
      "\t Some Kind of Wonderful (1987)\n",
      "\t Friday the 13th Part V: A New Beginning (1985)\n",
      "\t Out Cold (2001)\n",
      "\t New Guy, The (2002)\n",
      "\t Gaslight (1944)\n",
      "\t Road Trip (2000)\n",
      "Cluster #6\n",
      "\t Don Juan DeMarco (1995)\n",
      "\t For Whom the Bell Tolls (1943)\n",
      "\t Sixteen Candles (1984)\n",
      "\t On Her Majesty's Secret Service (1969)\n",
      "\t Making Mr. Right (1987)\n",
      "\t Swimming with Sharks (1995)\n",
      "\t Vanya on 42nd Street (1994)\n",
      "\t My Fair Lady (1964)\n",
      "\t High Noon (1952)\n",
      "\t My Favorite Year (1982)\n",
      "Cluster #7\n",
      "\t Secret of Roan Inish, The (1994)\n",
      "\t Journey of Natty Gann, The (1985)\n",
      "\t National Lampoon's Senior Trip (1995)\n",
      "\t Color of Night (1994)\n",
      "\t Ref, The (1994)\n",
      "\t Funny Face (1957)\n",
      "\t Naked Gun: From the Files of Police Squad!, The (1988)\n",
      "\t Babysitter, The (1995)\n",
      "\t Father of the Bride Part II (1995)\n",
      "\t Four Rooms (1995)\n",
      "Cluster #8\n",
      "\t Lost Weekend, The (1945)\n",
      "\t Being Human (1993)\n",
      "\t Hate (Haine, La) (1995)\n",
      "\t Inspector General, The (1949)\n",
      "\t Philadelphia Story, The (1940)\n",
      "\t Afterglow (1997)\n",
      "\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "\t Maltese Falcon, The (1941)\n",
      "\t Unforgiven (1992)\n",
      "\t Spy Who Loved Me, The (1977)\n",
      "Cluster #9\n",
      "\t Orlando (1992)\n",
      "\t Night of the Living Dead (1968)\n",
      "\t Crow: Salvation, The (2000)\n",
      "\t Battle Royale (Batoru rowaiaru) (2000)\n",
      "\t Safe (1995)\n",
      "\t Bubba Ho-tep (2002)\n",
      "\t Jane Eyre (1996)\n",
      "\t Interview with the Vampire: The Vampire Chronicles (1994)\n",
      "\t Ran (1985)\n",
      "\t Insider, The (1999)\n"
     ]
    }
   ],
   "source": [
    "movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
    "trained_movie_embeddings = model.movie_factors.weight.data.cpu().numpy()\n",
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)\n",
    "for cluster in range(10):\n",
    "  print(\"Cluster #{}\".format(cluster))\n",
    "  movs = []\n",
    "  for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "    movid = train_set.lookup[movidx]\n",
    "    # print(ratings_df.loc[ratings_df['movieId']==movid].count())\n",
    "    rat_count = ratings_df.loc[ratings_df['movieId']==movid].count()[\"userId\"]\n",
    "    movs.append((movie_names[movid], rat_count))\n",
    "  for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "    print(\"\\t\", mov[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
